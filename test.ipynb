{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import core\n",
    "from torchdrug import datasets, transforms,layers\n",
    "from torchdrug.core import Registry as R\n",
    "from torchdrug.layers import geometry\n",
    "\n",
    "import torch\n",
    "import torchdrug\n",
    "from torchdrug import data\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.use('Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:49:36   Extracting /home/cu/scratch/protein-datasets/EnzymeCommission.zip to /home/cu/scratch/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/cu/scratch/protein-datasets/EnzymeCommission/enzyme_commission.pkl.gz: 100%|██████████| 18716/18716 [00:24<00:00, 757.80it/s]\n"
     ]
    }
   ],
   "source": [
    "EnzymeCommission = R.search(\"datasets.EnzymeCommission\")\n",
    "PV = R.search(\"transforms.ProteinView\")\n",
    "trans = PV(view = \"residue\")\n",
    "dataset = EnzymeCommission(\"~/scratch/protein-datasets/\", test_cutoff=0.95, \n",
    "                           atom_feature=\"full\", bond_feature=\"full\", verbose=1, transform = trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示第一个样本的前两个残基的原子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein(num_atom=1596, num_bond=2920, num_residue=349)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cu/anaconda3/envs/gearnet/lib/python3.8/site-packages/torchdrug/data/molecule.py:586: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    }
   ],
   "source": [
    "# 数据集第一个样本，前两个残基的原子\n",
    "protein = dataset[0][\"graph\"]\n",
    "print(protein)\n",
    "is_first_two = (protein.residue_number == 1) | (protein.residue_number == 2) | (protein.residue_number == 3)\n",
    "first_two = protein.residue_mask(is_first_two, compact=True)\n",
    "\n",
    "first_two.visualize()\n",
    "#plt.savefig(\"fig/first_two_three.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedProtein(batch_size=2, num_atoms=[1596, 3761], num_bonds=[2920, 6468], num_residues=[349, 997])\n"
     ]
    }
   ],
   "source": [
    "first_two_elements = dataset[:2]\n",
    "graphs = [element[\"graph\"] for element in first_two_elements]\n",
    "protein2 = data.Protein.pack(graphs)\n",
    "print(protein2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试edge_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein(num_atom=1596, num_bond=2920, num_residue=349)\n",
      "tensor([[   1,    0,    0],\n",
      "        [   0,    1,    0],\n",
      "        [   2,    1,    0],\n",
      "        ...,\n",
      "        [1429, 1430,    0],\n",
      "        [1431, 1421,    0],\n",
      "        [1421, 1431,    0]])\n",
      "node_in:  tensor([   1,    0,    2,  ..., 1429, 1431, 1421])\n",
      "node_out:  tensor([   0,    1,    1,  ..., 1430, 1421, 1431])\n",
      "\n",
      "\n",
      "atom2residue: tensor([  0,   0,   0,  ..., 346, 347, 348])\n",
      "atom2residue.shape: torch.Size([1596])\n",
      "\n",
      "\n",
      "residue_in:  tensor([  0,   0,   0,  ..., 184, 184, 184])\n",
      "residue_out:  tensor([  0,   0,   0,  ..., 184, 184, 184])\n",
      "residue_in.shape:  torch.Size([2920])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = dataset[0][\"graph\"]\n",
    "print(graph)\n",
    "\n",
    "edge_list = graph.edge_list\n",
    "print(edge_list)\n",
    "\n",
    "num_relations = 7\n",
    "\n",
    "node_in, node_out, _ = edge_list.t()\n",
    "print(\"node_in: \", node_in)\n",
    "print(\"node_out: \", node_out)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"atom2residue:\", graph.atom2residue)\n",
    "print(\"atom2residue.shape:\", graph.atom2residue.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "residue_in, residue_out = graph.atom2residue[node_in], graph.atom2residue[node_out]\n",
    "print(\"residue_in: \", residue_in)\n",
    "print(\"residue_out: \", residue_out)\n",
    "print(\"residue_in.shape: \", residue_in.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只保留alpha碳，以及按照gearnet格式简化图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph before:  PackedProtein(batch_size=1, num_atoms=[1596], num_bonds=[2920], num_residues=[349])\n",
      "Graph after:  PackedProtein(batch_size=1, num_atoms=[185], num_bonds=[3754], num_residues=[185])\n",
      "node_feature:  torch.Size([185, 21])\n",
      "edge_feature:  torch.Size([3754, 59])\n",
      "edge_weight:  torch.Size([3754])\n",
      "node_position:  torch.Size([185, 3])\n",
      "new_edge_weight:  torch.Size([3754, 1]) tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "graph_construction_model = layers.GraphConstruction(node_layers=[geometry.AlphaCarbonNode()], \n",
    "                                                    edge_layers=[geometry.SpatialEdge(radius=10.0, min_distance=5),\n",
    "                                                                 geometry.KNNEdge(k=10, min_distance=5),\n",
    "                                                                 geometry.SequentialEdge(max_distance=2)\n",
    "                                                                 ],\n",
    "                                                    edge_feature=\"gearnet\"\n",
    "                                                    )\n",
    "\n",
    "_protein = data.Protein.pack([protein])\n",
    "protein_ = graph_construction_model(_protein)\n",
    "print(\"Graph before: \", _protein)\n",
    "print(\"Graph after: \", protein_)\n",
    "\n",
    "print(\"node_feature: \", protein_.node_feature.shape)\n",
    "print(\"edge_feature: \", protein_.edge_feature.shape)\n",
    "\n",
    "print(\"edge_weight: \", protein_.edge_weight.shape)\n",
    "\n",
    "print(\"node_position: \", protein_.node_position.shape)\n",
    "\n",
    "# 测试unsqueeze\n",
    "edge_weight = protein_.edge_weight.unsqueeze(-1)\n",
    "print(\"new_edge_weight: \", edge_weight.shape, edge_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gearnet 流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成稀疏的邻接矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([90, 85, 83,  ..., 75, 50, 51]) tensor([575, 547, 547,  ..., 749, 756, 756])\n",
      "torch.Size([3754]) torch.Size([3754])\n",
      "tensor(indices=tensor([[ 90,  85,  83,  ...,  75,  50,  51],\n",
      "                       [575, 547, 547,  ..., 749, 756, 756]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(185, 1295), nnz=3754, layout=torch.sparse_coo)\n",
      "torch.Size([185, 1295])\n"
     ]
    }
   ],
   "source": [
    "node_in, node_out, relation = protein_.edge_list.t()\n",
    "node_out = node_out * protein_.num_relation + relation\n",
    "print(node_in, node_out)\n",
    "print(node_in.shape, node_out.shape)\n",
    "\n",
    "import torchdrug.utils as utils\n",
    "adjacency = utils.sparse_coo_tensor(torch.stack([node_in, node_out]), protein_.edge_weight,\n",
    "                                    (protein_.num_node, protein_.num_node * protein_.num_relation))\n",
    "\n",
    "print(adjacency)\n",
    "print(adjacency.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGM模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph before:  PackedProtein(batch_size=2, num_atoms=[1596, 3761], num_bonds=[2920, 6468], num_residues=[349, 997])\n",
      "Graph after:  PackedProtein(batch_size=2, num_atoms=[185, 415], num_bonds=[3754, 8999], num_residues=[185, 415])\n",
      "\n",
      "\n",
      "graph_node_feature : torch.Size([600, 21])\n",
      "graph_edge_feature : torch.Size([12753, 59])\n",
      "\n",
      "\n",
      "graph_node _feature_type : torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein2_ = graph_construction_model(protein2)\n",
    "graph = protein2_\n",
    "#graph = protein_\n",
    "print(\"Graph before: \", protein2)\n",
    "print(\"Graph after: \", graph)\n",
    "print(\"\\n\")\n",
    "print(\"graph_node_feature :\",graph.node_feature.shape)\n",
    "print(\"graph_edge_feature :\",graph.edge_feature.shape)\n",
    "print(\"\\n\")\n",
    "print(\"graph_node _feature_type :\",graph.node_feature.dtype)\n",
    "\n",
    "len(graph.node_feature)\n",
    "#print(graph.node_feature.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(graph, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug.layers import functional\n",
    "\n",
    "# 定义一个简单的模型，包含SelfAttentionBlock\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.attention = layers.SelfAttentionBlock(hidden_dim = 512, num_heads = 8,dropout=0.1)\n",
    "        self. linear = layers.MultiLayerPerceptron(input_dim, \n",
    "                                                    hidden_dims = [512, 512], \n",
    "                                                    short_cut=True, \n",
    "                                                    batch_norm=True, \n",
    "                                                    activation=\"relu\")\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    \n",
    "    def forward(self, graph):  \n",
    "         \n",
    "        input = graph.node_feature.to(torch.float32)  # (num_nodes, input_dim)\n",
    "        mlp_output = self.linear(input)  # (num_nodes, hidden_dim)\n",
    "    \n",
    "        attn_input, sizes = functional._extend(mlp_output, graph.num_residues, mlp_output, graph.num_residues)\n",
    "        print(\"attn_input: \", attn_input.shape)\n",
    "        print(\"sizes: \", sizes)\n",
    "        attn_input, mask = functional.variadic_to_padded(attn_input, sizes)\n",
    "        print(\"mask: \", mask.shape)\n",
    "        print(\"attn_input: \", attn_input.shape)\n",
    "        \n",
    "        output = self.attention(mlp_output, mask)\n",
    "        #output = self.attention(mlp_output, mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_input:  torch.Size([1200, 512])\n",
      "sizes:  tensor([370, 830])\n",
      "mask:  torch.Size([2, 830])\n",
      "attn_input:  torch.Size([2, 830, 512])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 获取一个批次的数据并传递给模型\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#graph = batch['graph']\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/gearnet/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[85], line 28\u001b[0m, in \u001b[0;36mSimpleModel.forward\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask: \u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_input: \u001b[39m\u001b[38;5;124m\"\u001b[39m, attn_input\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 28\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#output = self.attention(mlp_output, mask)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/gearnet/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/gearnet/lib/python3.8/site-packages/torchdrug/layers/block.py:106\u001b[0m, in \u001b[0;36mSelfAttentionBlock.forward\u001b[0;34m(self, input, mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    105\u001b[0m mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m~\u001b[39mmask\u001b[38;5;241m.\u001b[39mbool())\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/gearnet/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/gearnet/lib/python3.8/site-packages/torch/nn/modules/activation.py:980\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m    970\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    977\u001b[0m         q_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight, k_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj_weight,\n\u001b[1;32m    978\u001b[0m         v_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj_weight)\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gearnet/lib/python3.8/site-packages/torch/nn/functional.py:4624\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   4596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tens_ops):\n\u001b[1;32m   4597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   4598\u001b[0m         multi_head_attention_forward,\n\u001b[1;32m   4599\u001b[0m         tens_ops,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4622\u001b[0m         static_v\u001b[38;5;241m=\u001b[39mstatic_v,\n\u001b[1;32m   4623\u001b[0m     )\n\u001b[0;32m-> 4624\u001b[0m tgt_len, bsz, embed_dim \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m embed_dim \u001b[38;5;241m==\u001b[39m embed_dim_to_check\n\u001b[1;32m   4626\u001b[0m \u001b[38;5;66;03m# allow MHA to have different sizes for the feature dimension\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "input_dim = graph.node_feature.shape[-1]\n",
    "num_heads = 8\n",
    "hidden_dim = 512\n",
    "model = SimpleModel(input_dim, num_heads, hidden_dim)\n",
    "\n",
    "# 获取一个批次的数据并传递给模型\n",
    "for batch in dataloader:\n",
    "    #graph = batch['graph']\n",
    "    output = model(graph)\n",
    "    print(\"Output:\", output)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    break  # 这里只查看一个批次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gearnet测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import models\n",
    "\n",
    "dataloader = data.DataLoader(graph, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "GN = models.GearNet(input_dim=21,\n",
    "                    hidden_dims=512,\n",
    "                    batch_norm=True,\n",
    "                    concat_hidden=True,\n",
    "                    short_cut=True,\n",
    "                    readout=\"sum\",\n",
    "                    num_relation=7,\n",
    "                    edge_input_dim=59\n",
    "                    )\n",
    "\n",
    "# 获取一个批次的数据并传递给模型\n",
    "for batch in dataloader:\n",
    "    #graph = batch['graph']\n",
    "    gearnet_output= GN(graph, graph.node_feature.to(torch.float32))\n",
    "    node_feature1 = gearnet_output[\"node_feature\"]\n",
    "    #print(\"hiddden_node_feature:\", node_feature1.shape)\n",
    "\n",
    "    break  # 这里只查看一个批次"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gearnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
