{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import core\n",
    "from torchdrug import datasets, transforms,layers\n",
    "from torchdrug.core import Registry as R\n",
    "from torchdrug.layers import geometry\n",
    "\n",
    "import torch\n",
    "import torchdrug\n",
    "from torchdrug import data\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.use('Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:24:45   Extracting /home/xiaotong/scratch/protein-datasets/EnzymeCommission.zip to /home/xiaotong/scratch/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/xiaotong/scratch/protein-datasets/EnzymeCommission/enzyme_commission.pkl.gz: 100%|██████████| 18716/18716 [00:45<00:00, 408.58it/s]\n"
     ]
    }
   ],
   "source": [
    "EnzymeCommission = R.search(\"datasets.EnzymeCommission\")\n",
    "PV = R.search(\"transforms.ProteinView\")\n",
    "trans = PV(view = \"residue\")\n",
    "dataset = EnzymeCommission(\"~/scratch/protein-datasets/\", test_cutoff=0.95, \n",
    "                           atom_feature=\"full\", bond_feature=\"full\", verbose=1, transform = trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示第一个样本的前两个残基的原子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein(num_atom=1596, num_bond=2920, num_residue=349)\n"
     ]
    }
   ],
   "source": [
    "# 数据集第一个样本，前两个残基的原子\n",
    "protein = dataset[0][\"graph\"]\n",
    "print(protein)\n",
    "is_first_two = (protein.residue_number == 1) | (protein.residue_number == 2) | (protein.residue_number == 3)\n",
    "first_two = protein.residue_mask(is_first_two, compact=True)\n",
    "\n",
    "first_two.visualize()\n",
    "#plt.savefig(\"fig/first_two_three.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedProtein(batch_size=2, num_atoms=[1596, 3761], num_bonds=[2920, 6468], num_residues=[349, 997])\n"
     ]
    }
   ],
   "source": [
    "first_two_elements = dataset[:2]\n",
    "graphs = [element[\"graph\"] for element in first_two_elements]\n",
    "protein2 = data.Protein.pack(graphs)\n",
    "print(protein2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试edge_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein(num_atom=1596, num_bond=2920, num_residue=349)\n",
      "tensor([[   1,    0,    0],\n",
      "        [   0,    1,    0],\n",
      "        [   2,    1,    0],\n",
      "        ...,\n",
      "        [1429, 1430,    0],\n",
      "        [1431, 1421,    0],\n",
      "        [1421, 1431,    0]])\n",
      "node_in:  tensor([   1,    0,    2,  ..., 1429, 1431, 1421])\n",
      "node_out:  tensor([   0,    1,    1,  ..., 1430, 1421, 1431])\n",
      "\n",
      "\n",
      "atom2residue: tensor([  0,   0,   0,  ..., 346, 347, 348])\n",
      "atom2residue.shape: torch.Size([1596])\n",
      "\n",
      "\n",
      "residue_in:  tensor([  0,   0,   0,  ..., 184, 184, 184])\n",
      "residue_out:  tensor([  0,   0,   0,  ..., 184, 184, 184])\n",
      "residue_in.shape:  torch.Size([2920])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = dataset[0][\"graph\"]\n",
    "print(graph)\n",
    "\n",
    "edge_list = graph.edge_list\n",
    "print(edge_list)\n",
    "\n",
    "num_relations = 7\n",
    "\n",
    "node_in, node_out, _ = edge_list.t()\n",
    "print(\"node_in: \", node_in)\n",
    "print(\"node_out: \", node_out)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"atom2residue:\", graph.atom2residue)\n",
    "print(\"atom2residue.shape:\", graph.atom2residue.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "residue_in, residue_out = graph.atom2residue[node_in], graph.atom2residue[node_out]\n",
    "print(\"residue_in: \", residue_in)\n",
    "print(\"residue_out: \", residue_out)\n",
    "print(\"residue_in.shape: \", residue_in.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只保留alpha碳，以及按照gearnet格式简化图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph before:  PackedProtein(batch_size=1, num_atoms=[1596], num_bonds=[2920], num_residues=[349])\n",
      "Graph after:  PackedProtein(batch_size=1, num_atoms=[185], num_bonds=[3754], num_residues=[185])\n",
      "node_feature:  torch.Size([185, 21])\n",
      "edge_feature:  torch.Size([3754, 59])\n",
      "edge_weight:  torch.Size([3754])\n",
      "node_position:  torch.Size([185, 3])\n",
      "new_edge_weight:  torch.Size([3754, 1]) tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "graph_construction_model = layers.GraphConstruction(node_layers=[geometry.AlphaCarbonNode()], \n",
    "                                                    edge_layers=[geometry.SpatialEdge(radius=10.0, min_distance=5),\n",
    "                                                                 geometry.KNNEdge(k=10, min_distance=5),\n",
    "                                                                 geometry.SequentialEdge(max_distance=2)\n",
    "                                                                 ],\n",
    "                                                    edge_feature=\"gearnet\"\n",
    "                                                    )\n",
    "\n",
    "_protein = data.Protein.pack([protein])\n",
    "protein_ = graph_construction_model(_protein)\n",
    "print(\"Graph before: \", _protein)\n",
    "print(\"Graph after: \", protein_)\n",
    "\n",
    "print(\"node_feature: \", protein_.node_feature.shape)\n",
    "print(\"edge_feature: \", protein_.edge_feature.shape)\n",
    "\n",
    "print(\"edge_weight: \", protein_.edge_weight.shape)\n",
    "\n",
    "print(\"node_position: \", protein_.node_position.shape)\n",
    "\n",
    "# 测试unsqueeze\n",
    "edge_weight = protein_.edge_weight.unsqueeze(-1)\n",
    "print(\"new_edge_weight: \", edge_weight.shape, edge_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gearnet 流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成稀疏的邻接矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([90, 85, 83,  ..., 75, 50, 51]) tensor([575, 547, 547,  ..., 749, 756, 756])\n",
      "torch.Size([3754]) torch.Size([3754])\n",
      "tensor(indices=tensor([[ 90,  85,  83,  ...,  75,  50,  51],\n",
      "                       [575, 547, 547,  ..., 749, 756, 756]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(185, 1295), nnz=3754, layout=torch.sparse_coo)\n",
      "torch.Size([185, 1295])\n"
     ]
    }
   ],
   "source": [
    "node_in, node_out, relation = protein_.edge_list.t()\n",
    "node_out = node_out * protein_.num_relation + relation\n",
    "print(node_in, node_out)\n",
    "print(node_in.shape, node_out.shape)\n",
    "\n",
    "import torchdrug.utils as utils\n",
    "adjacency = utils.sparse_coo_tensor(torch.stack([node_in, node_out]), protein_.edge_weight,\n",
    "                                    (protein_.num_node, protein_.num_node * protein_.num_relation))\n",
    "\n",
    "print(adjacency)\n",
    "print(adjacency.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGM模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph before:  PackedProtein(batch_size=2, num_atoms=[1596, 3761], num_bonds=[2920, 6468], num_residues=[349, 997])\n",
      "Graph after:  PackedProtein(batch_size=2, num_atoms=[185, 415], num_bonds=[3754, 8999], num_residues=[185, 415])\n",
      "\n",
      "\n",
      "graph_node_feature : torch.Size([600, 21])\n",
      "graph_edge_feature : torch.Size([12753, 59])\n",
      "\n",
      "\n",
      "graph_node _feature_type : torch.int64\n"
     ]
    }
   ],
   "source": [
    "protein2_ = graph_construction_model(protein2)\n",
    "graph = protein2_\n",
    "#graph = protein_\n",
    "print(\"Graph before: \", protein2)\n",
    "print(\"Graph after: \", graph)\n",
    "print(\"\\n\")\n",
    "print(\"graph_node_feature :\",graph.node_feature.shape)\n",
    "print(\"graph_edge_feature :\",graph.edge_feature.shape)\n",
    "print(\"\\n\")\n",
    "print(\"graph_node _feature_type :\",graph.node_feature.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(graph, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个简单的模型，包含SelfAttentionBlock\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.attention = layers.SelfAttentionBlock(hidden_dim, num_heads = 8,dropout=0.1)\n",
    "        self. linear = layers.MultiLayerPerceptron(input_dim, \n",
    "                                                    hidden_dims = [512, 512], \n",
    "                                                    short_cut=True, \n",
    "                                                    batch_norm=True, \n",
    "                                                    activation=\"relu\")\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    \n",
    "    def forward(self, graph):  \n",
    "         \n",
    "        input = graph.node_feature.to(torch.float32)  # (num_nodes, input_dim)\n",
    "        mlp_output = self.linear(input)  # (num_nodes, hidden_dim)\n",
    "    \n",
    "    \n",
    "        output = mlp_output\n",
    "        #output = self.attention(mlp_output, mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[ 1.1939, -0.3854,  1.0081,  ...,  0.0599, -0.2007,  0.0885],\n",
      "        [ 0.2033,  1.1762,  1.7222,  ...,  0.5834, -0.2820, -0.6760],\n",
      "        [ 0.8066, -0.4677,  1.4509,  ..., -0.0228, -0.1015, -0.3398],\n",
      "        ...,\n",
      "        [ 0.8066, -0.4677,  1.4509,  ..., -0.0228, -0.1015, -0.3398],\n",
      "        [ 0.8066, -0.4677,  1.4509,  ..., -0.0228, -0.1015, -0.3398],\n",
      "        [-0.1988, -0.3632,  0.2138,  ...,  1.0517,  0.0259, -0.4859]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Output shape: torch.Size([600, 512])\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "input_dim = graph.node_feature.shape[-1]\n",
    "num_heads = 8\n",
    "hidden_dim = 512\n",
    "model = SimpleModel(input_dim, num_heads, hidden_dim)\n",
    "\n",
    "# 获取一个批次的数据并传递给模型\n",
    "for batch in dataloader:\n",
    "    #graph = batch['graph']\n",
    "    output = model(graph)\n",
    "    print(\"Output:\", output)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    break  # 这里只查看一个批次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gearnet测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import models\n",
    "\n",
    "dataloader = data.DataLoader(graph, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 获取一个批次的数据并传递给模型\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m---> 13\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgraph\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m     output \u001b[38;5;241m=\u001b[39m GN(graph)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/gearnet/lib/python3.8/site-packages/torchdrug/data/graph.py:1469\u001b[0m, in \u001b[0;36mPackedGraph.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex indexing is not supported for PackedGraph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1469\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standarize_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m count \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mbincount(minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m count\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/gearnet/lib/python3.8/site-packages/torchdrug/data/graph.py:236\u001b[0m, in \u001b[0;36mGraph._standarize_index\u001b[0;34m(self, index, count)\u001b[0m\n\u001b[1;32m    234\u001b[0m     index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(start, stop, step, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    238\u001b[0m         index \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "GN = models.GearNet(input_dim=21,\n",
    "                    hidden_dims=512,\n",
    "                    batch_norm=True,\n",
    "                    concat_hidden=True,\n",
    "                    short_cut=True,\n",
    "                    readout=\"sum\",\n",
    "                    num_relation=7,\n",
    "                    edge_input_dim=59\n",
    "                    )\n",
    "\n",
    "# 获取一个批次的数据并传递给模型\n",
    "for batch in dataloader:\n",
    "    #graph = batch['graph']\n",
    "    output = GN(graph)\n",
    "    print(\"Output:\", output)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    break  # 这里只查看一个批次"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gearnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
