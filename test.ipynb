{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import core\n",
    "from torchdrug import datasets, transforms,layers\n",
    "from torchdrug.core import Registry as R\n",
    "from torchdrug.layers import geometry\n",
    "\n",
    "import torch\n",
    "import torchdrug\n",
    "from torchdrug import data\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.use('Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:08:53   Extracting /home/xiaotong/scratch/protein-datasets/EnzymeCommission.zip to /home/xiaotong/scratch/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/xiaotong/scratch/protein-datasets/EnzymeCommission/enzyme_commission.pkl.gz: 100%|██████████| 18716/18716 [00:44<00:00, 417.67it/s]\n"
     ]
    }
   ],
   "source": [
    "EnzymeCommission = R.search(\"datasets.EnzymeCommission\")\n",
    "PV = R.search(\"transforms.ProteinView\")\n",
    "trans = PV(view = \"residue\")\n",
    "dataset = EnzymeCommission(\"~/scratch/protein-datasets/\", test_cutoff=0.95, \n",
    "                           atom_feature=\"full\", bond_feature=\"full\", verbose=1, transform = trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示第一个样本的前两个残基的原子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein(num_atom=1596, num_bond=2920, num_residue=349)\n"
     ]
    }
   ],
   "source": [
    "# 数据集第一个样本，前两个残基的原子\n",
    "protein = dataset[0][\"graph\"]\n",
    "print(protein)\n",
    "is_first_two = (protein.residue_number == 1) | (protein.residue_number == 2) | (protein.residue_number == 3)\n",
    "first_two = protein.residue_mask(is_first_two, compact=True)\n",
    "\n",
    "first_two.visualize()\n",
    "#plt.savefig(\"fig/first_two_three.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedProtein(batch_size=2, num_atoms=[1596, 3761], num_bonds=[2920, 6468], num_residues=[349, 997])\n"
     ]
    }
   ],
   "source": [
    "first_two_elements = dataset[:2]\n",
    "graphs = [element[\"graph\"] for element in first_two_elements]\n",
    "protein2 = data.Protein.pack(graphs)\n",
    "print(protein2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试edge_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein(num_atom=1596, num_bond=2920, num_residue=349)\n",
      "tensor([[   1,    0,    0],\n",
      "        [   0,    1,    0],\n",
      "        [   2,    1,    0],\n",
      "        ...,\n",
      "        [1429, 1430,    0],\n",
      "        [1431, 1421,    0],\n",
      "        [1421, 1431,    0]])\n",
      "node_in:  tensor([   1,    0,    2,  ..., 1429, 1431, 1421])\n",
      "node_out:  tensor([   0,    1,    1,  ..., 1430, 1421, 1431])\n",
      "\n",
      "\n",
      "atom2residue: tensor([  0,   0,   0,  ..., 346, 347, 348])\n",
      "atom2residue.shape: torch.Size([1596])\n",
      "\n",
      "\n",
      "residue_in:  tensor([  0,   0,   0,  ..., 184, 184, 184])\n",
      "residue_out:  tensor([  0,   0,   0,  ..., 184, 184, 184])\n",
      "residue_in.shape:  torch.Size([2920])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = dataset[0][\"graph\"]\n",
    "print(graph)\n",
    "\n",
    "edge_list = graph.edge_list\n",
    "print(edge_list)\n",
    "\n",
    "num_relations = 7\n",
    "\n",
    "node_in, node_out, _ = edge_list.t()\n",
    "print(\"node_in: \", node_in)\n",
    "print(\"node_out: \", node_out)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"atom2residue:\", graph.atom2residue)\n",
    "print(\"atom2residue.shape:\", graph.atom2residue.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "residue_in, residue_out = graph.atom2residue[node_in], graph.atom2residue[node_out]\n",
    "print(\"residue_in: \", residue_in)\n",
    "print(\"residue_out: \", residue_out)\n",
    "print(\"residue_in.shape: \", residue_in.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只保留alpha碳，以及按照gearnet格式简化图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph before:  PackedProtein(batch_size=1, num_atoms=[1596], num_bonds=[2920], num_residues=[349])\n",
      "Graph after:  PackedProtein(batch_size=1, num_atoms=[185], num_bonds=[3754], num_residues=[185])\n",
      "node_feature:  torch.Size([185, 21])\n",
      "edge_feature:  torch.Size([3754, 59])\n",
      "edge_weight:  torch.Size([3754])\n",
      "node_position:  torch.Size([185, 3])\n",
      "new_edge_weight:  torch.Size([3754, 1]) tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "graph_construction_model = layers.GraphConstruction(node_layers=[geometry.AlphaCarbonNode()], \n",
    "                                                    edge_layers=[geometry.SpatialEdge(radius=10.0, min_distance=5),\n",
    "                                                                 geometry.KNNEdge(k=10, min_distance=5),\n",
    "                                                                 geometry.SequentialEdge(max_distance=2)\n",
    "                                                                 ],\n",
    "                                                    edge_feature=\"gearnet\"\n",
    "                                                    )\n",
    "\n",
    "_protein = data.Protein.pack([protein])\n",
    "protein_ = graph_construction_model(_protein)\n",
    "print(\"Graph before: \", _protein)\n",
    "print(\"Graph after: \", protein_)\n",
    "\n",
    "print(\"node_feature: \", protein_.node_feature.shape)\n",
    "print(\"edge_feature: \", protein_.edge_feature.shape)\n",
    "\n",
    "print(\"edge_weight: \", protein_.edge_weight.shape)\n",
    "\n",
    "print(\"node_position: \", protein_.node_position.shape)\n",
    "\n",
    "# 测试unsqueeze\n",
    "edge_weight = protein_.edge_weight.unsqueeze(-1)\n",
    "print(\"new_edge_weight: \", edge_weight.shape, edge_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGM模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedProtein(batch_size=2, num_atoms=[1596, 3761], num_bonds=[2920, 6468], num_residues=[349, 997])\n",
      "Graph before:  PackedProtein(batch_size=2, num_atoms=[1596, 3761], num_bonds=[2920, 6468], num_residues=[349, 997])\n",
      "Graph after:  PackedProtein(batch_size=2, num_atoms=[185, 415], num_bonds=[3754, 8999], num_residues=[185, 415])\n",
      "\n",
      "\n",
      "graph_node_feature : torch.Size([600, 21])\n",
      "graph_edge_feature : torch.Size([12753, 59])\n",
      "\n",
      "\n",
      "graph_node _feature_type : torch.int64\n",
      "\n",
      "\n",
      "graph.edge_list:  tensor([[ 95,  96,   5],\n",
      "        [109, 110,   5],\n",
      "        [108, 109,   5],\n",
      "        ...,\n",
      "        [438, 470,   0],\n",
      "        [489, 470,   0],\n",
      "        [493, 470,   0]])\n",
      "graph.edge_list.shape:  torch.Size([12753, 3])\n",
      "\n",
      "\n",
      "graph.edge_weight:  tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "graph.edge_weight.shape:  torch.Size([12753])\n"
     ]
    }
   ],
   "source": [
    "graphs = dataset[:2]\n",
    "graphs = [element[\"graph\"] for element in graphs]\n",
    "graphs = data.Protein.pack(graphs)\n",
    "print(graphs)\n",
    "protein2_ = graph_construction_model(graphs)\n",
    "graph = protein2_\n",
    "#graph = protein_\n",
    "print(\"Graph before: \", protein2)\n",
    "print(\"Graph after: \", graph)\n",
    "print(\"\\n\")\n",
    "print(\"graph_node_feature :\",graph.node_feature.shape)\n",
    "print(\"graph_edge_feature :\",graph.edge_feature.shape)\n",
    "print(\"\\n\")\n",
    "print(\"graph_node _feature_type :\",graph.node_feature.dtype)\n",
    "\n",
    "len(graph.node_feature)\n",
    "#print(graph.node_feature.max())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"graph.edge_list: \", graph.edge_list)\n",
    "print(\"graph.edge_list.shape: \", graph.edge_list.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"graph.edge_weight: \", graph.edge_weight)\n",
    "print(\"graph.edge_weight.shape: \", graph.edge_weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关系神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_mean, scatter_add, scatter_max\n",
    "import torch.nn as nn\n",
    "from torchdrug import utils\n",
    "from torch.utils import checkpoint\n",
    "\n",
    "class relationalGraph(layers. MessagePassingBase):\n",
    "    eps = 1e-10\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, num_relation, edge_input_dim=None, batch_norm=False, activation=\"relu\"):\n",
    "        super(relationalGraph, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_relation = num_relation\n",
    "        self.edge_input_dim = edge_input_dim\n",
    "\n",
    "        if batch_norm:\n",
    "            self.batch_norm = nn.BatchNorm1d(output_dim)\n",
    "        else:\n",
    "            self.batch_norm = None\n",
    "        if isinstance(activation, str):\n",
    "            self.activation = getattr(F, activation)\n",
    "        else:\n",
    "            self.activation = activation\n",
    "\n",
    "        #self.self_loop = nn.Linear(input_dim, output_dim)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        if edge_input_dim:\n",
    "            self.edge_linear = nn.Linear(edge_input_dim, input_dim)\n",
    "        else:\n",
    "            self.edge_linear = None\n",
    "\n",
    "    def message_and_aggregate(self, graph, input, edge_list, edge_weight):\n",
    "        assert graph.num_relation == self.num_relation\n",
    "\n",
    "        if edge_list is None:\n",
    "            node_in, node_out, relation = graph.edge_list.t()\n",
    "        else:\n",
    "            node_in, node_out, relation = edge_list.t()\n",
    "        node_out = node_out * self.num_relation + relation\n",
    "        if edge_weight is None:\n",
    "            degree_out = scatter_add(graph.edge_weight, node_out, dim_size=graph.num_node * graph.num_relation)\n",
    "            degree_out = degree_out+ self.eps\n",
    "            edge_weight = graph.edge_weight / degree_out[node_out]\n",
    "        else:\n",
    "            degree_out = scatter_add(edge_weight, node_out, dim_size=graph.num_node * graph.num_relation)\n",
    "            degree_out = degree_out+ self.eps\n",
    "            edge_weight = edge_weight / degree_out[node_out]\n",
    "        adjacency = utils.sparse_coo_tensor(torch.stack([node_in, node_out]), edge_weight,\n",
    "                                            (graph.num_node, graph.num_node * graph.num_relation))\n",
    "        update = torch.sparse.mm(adjacency.t(), input)\n",
    "        \n",
    "        if self.edge_linear:\n",
    "            edge_input = graph.edge_feature.float()\n",
    "            edge_input = self.edge_linear(edge_input)\n",
    "            edge_weight = edge_weight.unsqueeze(-1)\n",
    "            edge_update = scatter_add(edge_input * edge_weight, node_out, dim=0,\n",
    "                                      dim_size=graph.num_node * graph.num_relation)\n",
    "            update += edge_update\n",
    "\n",
    "        return update\n",
    "\n",
    "\n",
    "    def combine(self, input, update):\n",
    "        output = self.linear(update)\n",
    "        if self.batch_norm:\n",
    "            output = self.batch_norm(output)\n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, graph, input, edge_list, edge_weight):\n",
    "        \n",
    "        if self.gradient_checkpoint:\n",
    "            update = checkpoint.checkpoint(self._message_and_aggregate, *graph.to_tensors(), input)\n",
    "        else:\n",
    "            update = self.message_and_aggregate(graph, input, edge_list, edge_weight)\n",
    "        output = self.combine(input, update)\n",
    "        return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  torch.Size([4200, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = graph.node_feature.shape[-1]\n",
    "output_dim = 512\n",
    "num_relations = graph.num_relation\n",
    "\n",
    "output = relationalGraph(input_dim, output_dim, num_relations)(graph, graph.node_feature.float(),graph.edge_list, graph.edge_weight)\n",
    "print(\"output: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation_output:  torch.Size([600, 512])\n"
     ]
    }
   ],
   "source": [
    "def split_matrix(matrix, num_relation):\n",
    "    # 计算每份的行数\n",
    "    rows_per_split = matrix.shape[0] // num_relation\n",
    "\n",
    "    # 分割矩阵\n",
    "    split_matrices = []\n",
    "    for i in range(num_relation):\n",
    "        start_idx = i * rows_per_split\n",
    "        end_idx = start_idx + rows_per_split\n",
    "        split_matrices.append(matrix[start_idx:end_idx])\n",
    "\n",
    "    return split_matrices\n",
    "\n",
    "relation_output = split_matrix(output, graph.num_relation)\n",
    "\n",
    "print(\"relation_output: \", relation_output[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug.layers import functional\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_heads, temperature=0.5, dropout=0.1):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.out_features = out_features\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.query = nn.Linear(in_features, out_features * num_heads)\n",
    "        self.key = nn.Linear(in_features, out_features * num_heads)\n",
    "        self.value = nn.Linear(in_features, out_features * num_heads)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([out_features]))\n",
    "        \n",
    "\n",
    "    def forward(self, node_features, graph):\n",
    "        num_nodes = node_features.size(0)\n",
    "\n",
    "        # 计算查询、键和值，并为多头自注意力进行变形\n",
    "        Q = self.query(node_features).view(num_nodes, self.num_heads, self.out_features)  # [num_nodes, num_heads, out_features]\n",
    "        K = self.key(node_features).view(num_nodes, self.num_heads, self.out_features)    # [num_nodes, num_heads, out_features]\n",
    "        #V = self.value(node_features).view(num_nodes, self.num_heads, self.out_features)  # [num_nodes, num_heads, out_features]\n",
    "\n",
    "        # 计算相似性分数\n",
    "        scores = torch.einsum(\"nhd,mhd->nhm\", Q, K) / self.scale  # [num_heads, num_nodes, num_nodes]\n",
    "        \n",
    "        scores = scores / self.temperature\n",
    "\n",
    "        # 计算注意力权重\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # [num_heads, num_nodes, num_nodes]\n",
    "        \n",
    "        # 应用 dropout\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # 多头结果合并\n",
    "        attention_weights = attention_weights.mean(dim=-2)  # [num_nodes, num_nodes]\n",
    "\n",
    "        return attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算rewire得分的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_edge_list:  tensor([[  0, 521,   0],\n",
      "        [  0, 278,   0],\n",
      "        [  0, 439,   0],\n",
      "        ...,\n",
      "        [599, 353,   6],\n",
      "        [599, 234,   6],\n",
      "        [599,  99,   6]])\n",
      "new_edge_weight:  tensor([0.5719, 0.5117, 0.4379,  ..., 0.4188, 0.4009, 0.3803])\n",
      "output:  torch.Size([12600]) torch.Size([12600, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdrug import layers, utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Combinedlayer(nn.Module):\n",
    "    \n",
    "    eps = 1e-10\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, num_relation, edge_input_dim, \n",
    "                 num_heads = 8 , attention_out_features  = 512, temperature=0.5, dropout=0.1):\n",
    "        super(Combinedlayer, self).__init__()\n",
    "        \n",
    "        self.relational_graph = relationalGraph(input_dim, output_dim, num_relation, edge_input_dim)\n",
    "        self.attention = MultiHeadSelfAttention(output_dim, attention_out_features, num_heads, temperature, dropout)\n",
    "    \n",
    "    def split_matrix(self,matrix, num_relation):\n",
    "        # 计算每份的行数\n",
    "        rows_per_split = matrix.shape[0] // num_relation\n",
    "\n",
    "        # 分割矩阵\n",
    "        split_matrices = []\n",
    "        for i in range(num_relation):\n",
    "            start_idx = i * rows_per_split\n",
    "            end_idx = start_idx + rows_per_split\n",
    "            split_matrices.append(matrix[start_idx:end_idx])\n",
    "\n",
    "        return split_matrices\n",
    "    \n",
    "    \n",
    "    def merge_relation_matrices(self,matrix_list):\n",
    "        merged_list = []\n",
    "\n",
    "        # 遍历每个矩阵\n",
    "        for idx, matrix in enumerate(matrix_list):\n",
    "            num_rows = matrix.size(0)\n",
    "            # 创建一个形状为 [num_rows, 1] 的张量，记录矩阵索引\n",
    "            relation_idx = torch.full((num_rows, 1), idx, dtype=torch.long)\n",
    "            # 将矩阵和索引列拼接在一起\n",
    "            extended_matrix = torch.cat((matrix, relation_idx), dim=1)\n",
    "            merged_list.append(extended_matrix)\n",
    "        \n",
    "        # 将所有扩展后的矩阵合并成一个矩阵\n",
    "        merged_matrix = torch.cat(merged_list, dim=0)\n",
    "        \n",
    "        return merged_matrix\n",
    "\n",
    "    def process_list(self, tensor_list):\n",
    "        result_list = []\n",
    "        edge_weights_list = []\n",
    "\n",
    "        for matrix in tensor_list:\n",
    "            num_nodes = matrix.size(0)\n",
    "            indices_list = []\n",
    "            values_list = []\n",
    "\n",
    "            for i in range(num_nodes):\n",
    "                row = matrix[i]\n",
    "                # 找到前3个最大的数及其索引\n",
    "                sorted_indices = torch.argsort(row, descending=True)  # 从大到小排序\n",
    "                max_values = row[sorted_indices][:5]\n",
    "\n",
    "                # 检查是否有超过3个相同的最大数\n",
    "                count = (row == max_values[-1]).sum().item()\n",
    "\n",
    "                if count > 3:\n",
    "                    # 选择与当前行序号距离最近的列索引\n",
    "                    relevant_indices = sorted_indices[:count]\n",
    "                    distances = torch.abs(relevant_indices - i)\n",
    "                    closest_indices = relevant_indices[torch.argsort(distances)][:3]\n",
    "                    selected_indices = closest_indices\n",
    "                else:\n",
    "                    selected_indices = sorted_indices[:3]\n",
    "\n",
    "                # 记录当前行号、所选列号和对应的值\n",
    "                for j in selected_indices:\n",
    "                    indices_list.append([i, j.item()])\n",
    "                    values_list.append(row[j].item())\n",
    "\n",
    "            result_matrix = torch.tensor(indices_list, dtype=torch.long)\n",
    "            result_list.append(result_matrix)\n",
    "            edge_weights_list.append(torch.tensor(values_list, dtype=torch.float))\n",
    "\n",
    "        return self.merge_relation_matrices(result_list), torch.cat(edge_weights_list).view(-1, 1)\n",
    "\n",
    "    \n",
    "    def normalize_edge_weights(self,edge_weights):\n",
    "        min_weight = edge_weights.min()\n",
    "        max_weight = edge_weights.max()\n",
    "        normalized_weights = (edge_weights - min_weight) / (max_weight - min_weight + self.eps)\n",
    "        return normalized_weights\n",
    "\n",
    "    \n",
    "    def forward(self, node_features, graph, edge_list, edge_weight):\n",
    "        # Apply relational graph layer\n",
    "        relational_output = self.relational_graph(graph, node_features, edge_list, edge_weight)\n",
    "        \n",
    "        relational_output = self.split_matrix(relational_output, graph.num_relation)\n",
    "        #print(\"relational_output: \", len(relational_output))\n",
    "        \n",
    "        attention_output = []\n",
    "        for i in range(len(relational_output)):\n",
    "            # Apply multi-head self attention\n",
    "            output = self.attention(relational_output[i], graph)\n",
    "            attention_output.append(output)\n",
    "            \n",
    "        #print(\"attention_output: \", attention_output)\n",
    "        new_edge_list, new_edge_weight = self.process_list(attention_output)\n",
    "        new_edge_weight = new_edge_weight.squeeze()  # 去掉多余的维度\n",
    "        new_edge_weight = self.normalize_edge_weights(new_edge_weight)\n",
    "        \n",
    "        # 调试信息\n",
    "        print(\"new_edge_list: \", new_edge_list)\n",
    "        print(\"new_edge_weight: \", new_edge_weight)\n",
    "        \n",
    "        \n",
    "        return new_edge_list, new_edge_weight\n",
    "    \n",
    "\n",
    "# Example of how to initialize and use the model\n",
    "input_dim = graph.node_feature.shape[-1]\n",
    "output_dim = 512\n",
    "num_relation = graph.num_relation\n",
    "edge_input_dim = graph.edge_feature.shape[-1]\n",
    "num_heads = 8\n",
    "attention_out_features = 512\n",
    "\n",
    "model = Combinedlayer(input_dim, output_dim, num_relation, edge_input_dim, \n",
    "                      num_heads, attention_out_features)\n",
    "\n",
    "\n",
    "\n",
    "edge_list_output, edge_weight_output = model(graph.node_feature.float(), graph,graph.edge_list, graph.edge_weight)\n",
    "print(\"output: \", edge_weight_output.shape, edge_list_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import layers\n",
    "from torch.utils import checkpoint\n",
    "\n",
    "class rewireGeometricRelationalGraphConv(layers.RelationalGraphConv):\n",
    "    gradient_checkpoint = False\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, num_relation, edge_input_dim=None, batch_norm=False, activation=\"relu\"):\n",
    "        super(rewireGeometricRelationalGraphConv, self).__init__(input_dim, output_dim, num_relation, edge_input_dim,\n",
    "                                                           batch_norm, activation)\n",
    "\n",
    "    def aggregate(self, graph, message, new_edge_list):\n",
    "        assert graph.num_relation == self.num_relation\n",
    "\n",
    "        if new_edge_list is None:\n",
    "            node_out = graph.edge_list[:, 1] * self.num_relation + graph.edge_list[:, 2]\n",
    "        else:\n",
    "            node_out = new_edge_list[:, 1] * self.num_relation + new_edge_list[:, 2]\n",
    "        edge_weight = graph.edge_weight.unsqueeze(-1)\n",
    "        update = scatter_add(message * edge_weight, node_out, dim=0, dim_size=graph.num_node * self.num_relation)\n",
    "        update = update.view(graph.num_node, self.num_relation * self.input_dim)\n",
    "\n",
    "        return update\n",
    "\n",
    "\n",
    "    def message_and_aggregate(self, graph, input, new_edge_list, new_edge_weight):\n",
    "        assert graph.num_relation == self.num_relation\n",
    "\n",
    "        if new_edge_list is None:\n",
    "            node_in, node_out, relation = graph.edge_list.t()\n",
    "        else:\n",
    "            node_in, node_out, relation = new_edge_list.t()\n",
    "        node_out = node_out * self.num_relation + relation\n",
    "        if new_edge_weight is None:\n",
    "            adjacency = utils.sparse_coo_tensor(torch.stack([node_in, node_out]), graph.edge_weight,\n",
    "                                            (graph.num_node, graph.num_node * graph.num_relation))\n",
    "        else:\n",
    "            adjacency = utils.sparse_coo_tensor(torch.stack([node_in, node_out]), new_edge_weight,\n",
    "                                            (graph.num_node, graph.num_node * graph.num_relation))\n",
    "        update = torch.sparse.mm(adjacency.t(), input)\n",
    "        \n",
    "        if self.edge_linear:\n",
    "            edge_input = graph.edge_feature.float()\n",
    "            edge_input = self.edge_linear(edge_input)\n",
    "            if new_edge_weight is None:\n",
    "                edge_weight = graph.edge_weight.unsqueeze(-1)\n",
    "            else:\n",
    "                edge_weight = new_edge_weight.unsqueeze(-1)\n",
    "            edge_update = scatter_add(edge_input * edge_weight, node_out, dim=0,\n",
    "                                    dim_size=graph.num_node * graph.num_relation)\n",
    "            update += edge_update\n",
    "            \n",
    "        return update.view(graph.num_node, self.num_relation * self.input_dim)\n",
    "    \n",
    "    def forward(self, graph, input, new_edge_list=None, new_edge_weight = None):\n",
    "        \"\"\"\n",
    "        Perform message passing over the graph(s).\n",
    "\n",
    "        Parameters:\n",
    "            graph (Graph): graph(s)\n",
    "            input (Tensor): node representations of shape :math:`(|V|, ...)`\n",
    "        \"\"\"\n",
    "        if self.gradient_checkpoint:\n",
    "            update = checkpoint.checkpoint(self._message_and_aggregate, *graph.to_tensors(), input)\n",
    "        else:\n",
    "            update = self.message_and_aggregate(graph, input, new_edge_list, new_edge_weight)\n",
    "        output = self.combine(input, update)\n",
    "        return output\n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedProtein(batch_size=2, num_atoms=[1596, 3761], num_bonds=[2920, 6468], num_residues=[349, 997])\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import core, layers\n",
    "from torchdrug.core import Registry as R\n",
    "\n",
    "graphs = dataset[:2]\n",
    "graphs = [element[\"graph\"] for element in graphs]\n",
    "graphs = data.Protein.pack(graphs)\n",
    "print(graphs)\n",
    "graph = graph_construction_model(graphs)\n",
    "\n",
    "\n",
    "#@R.register(\"models.DGMGearNet\")\n",
    "class DGMGeometryAwareRelationalGraphNeuralNetwork(nn.Module, core.Configurable):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dims, num_relation, edge_input_dim=None, num_angle_bin=None,\n",
    "                 short_cut=False, batch_norm=False, activation=\"relu\", concat_hidden=False, readout=\"sum\"):\n",
    "        super(DGMGeometryAwareRelationalGraphNeuralNetwork, self).__init__()\n",
    "\n",
    "        #if not isinstance(hidden_dims, Sequence):\n",
    "            #hidden_dims = [hidden_dims]\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = sum(hidden_dims) if concat_hidden else hidden_dims[-1]\n",
    "        self.dims = [input_dim] + list(hidden_dims)\n",
    "        self.edge_dims = [edge_input_dim] + self.dims[:-1]\n",
    "        self.num_relation = num_relation\n",
    "        self.num_angle_bin = num_angle_bin\n",
    "        self.short_cut = short_cut\n",
    "        self.concat_hidden = concat_hidden\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.combined_layers = nn.ModuleList()\n",
    "        for i in range(len(self.dims) - 1):\n",
    "            \n",
    "            self.combined_layers.append(Combinedlayer(self.dims[i], self.dims[i + 1], num_relation, edge_input_dim, \n",
    "                                             num_heads=8, attention_out_features=512))\n",
    "            self.layers.append(rewireGeometricRelationalGraphConv(self.dims[i], self.dims[i + 1], num_relation,\n",
    "                                                                   None, batch_norm, activation))\n",
    "        if num_angle_bin:\n",
    "            self.spatial_line_graph = layers.SpatialLineGraph(num_angle_bin)\n",
    "            self.edge_layers = nn.ModuleList()\n",
    "            for i in range(len(self.edge_dims) - 1):\n",
    "                self.edge_layers.append(layers.GeometricRelationalGraphConv(\n",
    "                    self.edge_dims[i], self.edge_dims[i + 1], num_angle_bin, None, batch_norm, activation))\n",
    "\n",
    "        if batch_norm:\n",
    "            self.batch_norms = nn.ModuleList()\n",
    "            for i in range(len(self.dims) - 1):\n",
    "                self.batch_norms.append(nn.BatchNorm1d(self.dims[i + 1]))\n",
    "\n",
    "        if readout == \"sum\":\n",
    "            self.readout = layers.SumReadout()\n",
    "        elif readout == \"mean\":\n",
    "            self.readout = layers.MeanReadout()\n",
    "        else:\n",
    "            raise ValueError(\"Unknown readout `%s`\" % readout)\n",
    "\n",
    "    def forward(self, graph, input, all_loss=None, metric=None, edge_list=None, edge_weight=None):\n",
    "        \"\"\"\n",
    "        Compute the node representations and the graph representation(s).\n",
    "\n",
    "        Parameters:\n",
    "            graph (Graph): :math:`n` graph(s)\n",
    "            input (Tensor): input node representations\n",
    "            all_loss (Tensor, optional): if specified, add loss to this tensor\n",
    "            metric (dict, optional): if specified, output metrics to this dict\n",
    "\n",
    "        Returns:\n",
    "            dict with ``node_feature`` and ``graph_feature`` fields:\n",
    "                node representations of shape :math:`(|V|, d)`, graph representations of shape :math:`(n, d)`\n",
    "        \"\"\"\n",
    "        hiddens = []\n",
    "        layer_input = input\n",
    "        if self.num_angle_bin:\n",
    "            line_graph = self.spatial_line_graph(graph)\n",
    "            edge_input = line_graph.node_feature.float()\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            \n",
    "            \n",
    "            new_edge_list, new_edge_weight = self.combined_layers[i]( layer_input, graph, edge_list, edge_weight)\n",
    "            hidden = self.layers[i](graph, layer_input, new_edge_list, new_edge_weight)\n",
    "            if self.short_cut and hidden.shape == layer_input.shape:\n",
    "                hidden = hidden + layer_input\n",
    "            if self.num_angle_bin:\n",
    "                edge_hidden = self.edge_layers[i](line_graph, edge_input)\n",
    "                edge_weight = graph.edge_weight.unsqueeze(-1)\n",
    "                if new_edge_list is None:\n",
    "                    node_out = graph.edge_list[:, 1] * self.num_relation + graph.edge_list[:, 2]\n",
    "                else:\n",
    "                    node_out = new_edge_list[:, 1] * self.num_relation + new_edge_list[:, 2]\n",
    "                if new_edge_weight is None:\n",
    "                    update = scatter_add(edge_hidden * edge_weight, node_out, dim=0,\n",
    "                                        dim_size=graph.num_node * self.num_relation)\n",
    "                else:\n",
    "                    update = scatter_add(edge_hidden * edge_weight, node_out, dim=0,\n",
    "                                        dim_size=graph.num_node * self.num_relation)\n",
    "                update = update.view(graph.num_node, self.num_relation * edge_hidden.shape[1])\n",
    "                update = self.layers[i].linear(update)\n",
    "                update = self.layers[i].activation(update)\n",
    "                hidden = hidden + update\n",
    "                edge_input = edge_hidden\n",
    "            if self.batch_norm:\n",
    "                hidden = self.batch_norms[i](hidden)\n",
    "                \n",
    "            hiddens.append(hidden)\n",
    "            layer_input = hidden\n",
    "            edge_list = new_edge_list\n",
    "            edge_weight = new_edge_weight\n",
    "\n",
    "        if self.concat_hidden:\n",
    "            node_feature = torch.cat(hiddens, dim=-1)\n",
    "        else:\n",
    "            node_feature = hiddens[-1]\n",
    "        graph_feature = self.readout(graph, node_feature)\n",
    "        print(\"node_feature: \", node_feature.shape)\n",
    "\n",
    "        return {\n",
    "            \"graph_feature\": graph_feature,\n",
    "            \"node_feature\": node_feature\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_edge_list:  tensor([[  0,  11,   0],\n",
      "        [  0,  19,   0],\n",
      "        [  0,  87,   0],\n",
      "        ...,\n",
      "        [599, 402,   6],\n",
      "        [599, 378,   6],\n",
      "        [599, 214,   6]])\n",
      "new_edge_weight:  tensor([0.4229, 0.4229, 0.4229,  ..., 0.5700, 0.5700, 0.5700])\n",
      "new_edge_list:  tensor([[  0, 578,   0],\n",
      "        [  0, 579,   0],\n",
      "        [  0, 580,   0],\n",
      "        ...,\n",
      "        [599, 158,   6],\n",
      "        [599, 589,   6],\n",
      "        [599, 337,   6]])\n",
      "new_edge_weight:  tensor([0.0075, 0.0075, 0.0075,  ..., 0.2301, 0.1163, 0.1158])\n",
      "new_edge_list:  tensor([[  0,  14,   0],\n",
      "        [  0,  21,   0],\n",
      "        [  0,  37,   0],\n",
      "        ...,\n",
      "        [599, 567,   6],\n",
      "        [599, 558,   6],\n",
      "        [599, 557,   6]])\n",
      "new_edge_weight:  tensor([0.0633, 0.0633, 0.0633,  ..., 0.0884, 0.0884, 0.0884])\n",
      "node_feature:  torch.Size([600, 512])\n"
     ]
    }
   ],
   "source": [
    "output = DGMGeometryAwareRelationalGraphNeuralNetwork(input_dim = 21, hidden_dims=[512, 512, 512], num_relation=7)(graph, graph.node_feature.float())\n",
    "#print(\"output: \", output[\"graph_feature\"].shape, output[\"node_feature\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted sum of Soft Top-K min values per row:\n",
      "tensor([0.8992, 0.8003])\n",
      "Soft Top-K min indices per row:\n",
      "tensor([[2, 4, 1],\n",
      "        [3, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def soft_top_k_min(score_matrix, k=3, tau=1.0, eps=1e-10):\n",
    "    \"\"\"\n",
    "    使用 Soft Top-K 近似选择最小的 K 个值\n",
    "    :param score_matrix: 得分矩阵\n",
    "    :param k: 每行选择的最小值数量\n",
    "    :param tau: 温度参数\n",
    "    :param eps: 防止 log(0)\n",
    "    :return: 近似的最小 K 个值及其索引\n",
    "    \"\"\"\n",
    "    # 计算负得分\n",
    "    neg_score_matrix = -score_matrix\n",
    "    \n",
    "    # 生成 Gumbel 噪声\n",
    "    gumbel_noise = -torch.log(-torch.log(torch.rand_like(neg_score_matrix) + eps) + eps)\n",
    "    \n",
    "    # 扰动负得分矩阵\n",
    "    perturbed_scores = neg_score_matrix + gumbel_noise\n",
    "    \n",
    "    # 应用 softmax\n",
    "    softmax_probs = F.softmax(perturbed_scores / tau, dim=-1)\n",
    "    \n",
    "    # 获取前 k 个 softmax 权重的索引\n",
    "    topk_probs, topk_indices = softmax_probs.topk(k=k, dim=-1)\n",
    "    \n",
    "    # 根据索引获取相应的原始得分\n",
    "    topk_scores = torch.gather(score_matrix, 1, topk_indices)\n",
    "    \n",
    "    # 计算加权平均值\n",
    "    weighted_sum = torch.sum(topk_probs * topk_scores, dim=-1)\n",
    "    \n",
    "    return weighted_sum, topk_indices\n",
    "\n",
    "# 示例得分矩阵\n",
    "score_matrix = torch.tensor([[2.0, 1.0, 0.1, 3.5, 2.5],\n",
    "                             [0.5, 1.5, 1.0, 0.8, 2.2]])\n",
    "\n",
    "# 进行 Soft Top-K 近似\n",
    "k = 3  # 每行选择的最小值数量\n",
    "tau = 1.0  # 温度参数\n",
    "min_values, min_indices = soft_top_k_min(score_matrix, k=k, tau=tau)\n",
    "\n",
    "print(\"Weighted sum of Soft Top-K min values per row:\")\n",
    "print(min_values)\n",
    "\n",
    "print(\"Soft Top-K min indices per row:\")\n",
    "print(min_indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gearnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
